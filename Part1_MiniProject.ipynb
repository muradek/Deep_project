{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "$$\n",
    "\n",
    "# Part 1: Mini-Project\n",
    "<a id=part3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you'll implement a small comparative-analysis project, heavily based on the materials from the tutorials and homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You should implement the code which displays your results in this notebook, and add any additional code files for your implementation in the `project/` directory. You can import these files here, as we do for the homeworks.\n",
    "- Running this notebook should not perform any training - load your results from some output files and display them here. The notebook must be runnable from start to end without errors.\n",
    "- You must include a detailed write-up (in the notebook) of what you implemented and how. \n",
    "- Explain the structure of your code and how to run it to reproduce your results.\n",
    "- Explicitly state any external code you used, including built-in pytorch models and code from the course tutorials/homework.\n",
    "- Analyze your numerical results, explaining **why** you got these results (not just specifying the results).\n",
    "- Where relevant, place all results in a table or display them using a graph.\n",
    "- Before submitting, make sure all files which are required to run this notebook are included in the generated submission zip.\n",
    "- Try to keep the submission file size under 10MB. Do not include model checkpoint files, dataset files, or any other non-essentials files. Instead include your results as images/text files/pickles/etc, and load them for display in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection on TACO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TACO is a growing image dataset of waste in the wild. It contains images of litter taken under diverse environments: woods, roads and beaches.\n",
    "\n",
    "<center><img src=\"imgs/taco.png\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can read more about the dataset here: https://github.com/pedropro/TACO\n",
    "\n",
    "and can explore the data distribution and how to load it from here: https://github.com/pedropro/TACO/blob/master/demo.ipynb\n",
    "\n",
    "\n",
    "The stable version of the dataset that contain 1500 images and 4787 annotations exist in `datasets/TACO-master`\n",
    "You do not need to download the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project goals:\n",
    "\n",
    "* You need to perform Object Detection task, over 7 of the dataset.\n",
    "* The annotation for object detection can be downloaded from here: https://github.com/wimlds-trojmiasto/detect-waste/tree/main/annotations.\n",
    "* The data and annotation format is like the COCOAPI: https://github.com/cocodataset/cocoapi (you can find a notebook of how to perform evalutation using it here: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb)\n",
    "(you need to install it..)\n",
    "* if you need a beginner guild for OD in COCOAPI, you can read and watch this link: https://www.neuralception.com/cocodatasetapi/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do i need to do?\n",
    "\n",
    "* **Everything is in the game!** as long as your model does not require more then 8 GB of memory and you follow the Guidelines above.\n",
    "\n",
    "\n",
    "### What does it mean?\n",
    "* you can use data augmentation, rather take what's implemented in the directory or use external libraries such as https://albumentations.ai/ (notice that when you create your own augmentations you need to change the annotation as well)\n",
    "* you can use more data if you find it useful (for examples, reviwew https://github.com/AgaMiko/waste-datasets-review)\n",
    "\n",
    "\n",
    "### What model can i use?\n",
    "* Whatever you want!\n",
    "you can review good models for the coco-OD task as a referance:\n",
    "SOTA: https://paperswithcode.com/sota/object-detection-on-coco\n",
    "Real-Time: https://paperswithcode.com/sota/real-time-object-detection-on-coco\n",
    "Or you can use older models like YOLO-V3 or Faster-RCNN\n",
    "* As long as you have a reason (complexity, speed, preformence), you are golden.\n",
    "\n",
    "### Tips for a good grade:\n",
    "* start as simple as possible. dealing with APIs are not the easiest for the first time and i predict that this would be your main issue. only when you have a running model that learn, you can add learning tricks.\n",
    "* use the visualization of a notebook, as we did over the course, check that your input actually fitting the model, the output is the desired size and so on.\n",
    "* It is recommanded to change the images to a fixed size, like shown in here :https://github.com/pedropro/TACO/blob/master/detector/inspect_data.ipynb\n",
    "* Please adress the architecture and your loss function/s in this notebook. if you decided to add some loss component like the Focal loss for instance, try to show the results before and after using it.\n",
    "* Plot your losses in this notebook, any evaluation metric can be shown as a function of time and possibe to analize per class.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: This is where you should write your explanations and implement the code to display the results.\n",
    "See guidelines about what to include in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "from project.model_training import load_from_roboflow, set_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = load_from_roboflow()\n",
    "# %store dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "dataset             -> <roboflow.core.dataset.Dataset object at 0x7f85b28\n"
     ]
    }
   ],
   "source": [
    "# load the dataset var\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model, train_res, val_res = set_model(dataset, \"yolov8l.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the pretrained model\n",
    "model = YOLO(\"/home/muradek/Deep_project/runs/detect/train21/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.59 ðŸš€ Python-3.8.12 torch-1.10.1 CUDA:0 (NVIDIA GeForce RTX 2080, 7982MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/muradek/Deep_project/TACO-train_test-1/valid/labels.cache... 300 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<?, ?it/s]\u001b[0m\n",
      "This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:27<00:00,  1.45s/it]\n",
      "                   all        300       1011      0.363      0.208       0.14      0.099\n",
      "                   bio        300          2          1          0     0.0098    0.00742\n",
      "                 glass        300         66      0.203     0.0455     0.0397      0.029\n",
      "    metals_and_plastic        300        497      0.406      0.477       0.42      0.319\n",
      "        non_recyclable        300        259      0.255      0.247      0.146      0.105\n",
      "                 paper        300         63      0.138      0.405      0.171        0.1\n",
      "               unknown        300        124      0.177     0.0726     0.0529     0.0332\n",
      "Speed: 0.8ms preprocess, 24.5ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "Saving runs/detect/val10/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished predicting\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (2996545554.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    return pred_results\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# pred_res = pred(model, dataset)\n",
    "\n",
    "print(\"started testing\")\n",
    "#source = str(dataset.location) + \"/test/images\"\n",
    "# pred_results = model.predict(source=source, save=True, save_json=True)\n",
    "data = str(dataset.location) + \"/data.yaml\"\n",
    "pred_results = model.val(data=data, save_json=True)\n",
    "print(\"finished predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "db2aeb4a2d20d8f60ca10a95a693e4fbc8d4e86da5b1f77d6fc445990905a603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
