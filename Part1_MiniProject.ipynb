{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "$$\n",
    "\n",
    "# Part 1: Mini-Project\n",
    "<a id=part3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you'll implement a small comparative-analysis project, heavily based on the materials from the tutorials and homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You should implement the code which displays your results in this notebook, and add any additional code files for your implementation in the `project/` directory. You can import these files here, as we do for the homeworks.\n",
    "- Running this notebook should not perform any training - load your results from some output files and display them here. The notebook must be runnable from start to end without errors.\n",
    "- You must include a detailed write-up (in the notebook) of what you implemented and how. \n",
    "- Explain the structure of your code and how to run it to reproduce your results.\n",
    "- Explicitly state any external code you used, including built-in pytorch models and code from the course tutorials/homework.\n",
    "- Analyze your numerical results, explaining **why** you got these results (not just specifying the results).\n",
    "- Where relevant, place all results in a table or display them using a graph.\n",
    "- Before submitting, make sure all files which are required to run this notebook are included in the generated submission zip.\n",
    "- Try to keep the submission file size under 10MB. Do not include model checkpoint files, dataset files, or any other non-essentials files. Instead include your results as images/text files/pickles/etc, and load them for display in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection on TACO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TACO is a growing image dataset of waste in the wild. It contains images of litter taken under diverse environments: woods, roads and beaches.\n",
    "\n",
    "<center><img src=\"imgs/taco.png\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can read more about the dataset here: https://github.com/pedropro/TACO\n",
    "\n",
    "and can explore the data distribution and how to load it from here: https://github.com/pedropro/TACO/blob/master/demo.ipynb\n",
    "\n",
    "\n",
    "The stable version of the dataset that contain 1500 images and 4787 annotations exist in `datasets/TACO-master`\n",
    "You do not need to download the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project goals:\n",
    "\n",
    "* You need to perform Object Detection task, over 7 of the dataset.\n",
    "* The annotation for object detection can be downloaded from here: https://github.com/wimlds-trojmiasto/detect-waste/tree/main/annotations.\n",
    "* The data and annotation format is like the COCOAPI: https://github.com/cocodataset/cocoapi (you can find a notebook of how to perform evalutation using it here: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb)\n",
    "(you need to install it..)\n",
    "* if you need a beginner guild for OD in COCOAPI, you can read and watch this link: https://www.neuralception.com/cocodatasetapi/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do i need to do?\n",
    "\n",
    "* **Everything is in the game!** as long as your model does not require more then 8 GB of memory and you follow the Guidelines above.\n",
    "\n",
    "\n",
    "### What does it mean?\n",
    "* you can use data augmentation, rather take what's implemented in the directory or use external libraries such as https://albumentations.ai/ (notice that when you create your own augmentations you need to change the annotation as well)\n",
    "* you can use more data if you find it useful (for examples, reviwew https://github.com/AgaMiko/waste-datasets-review)\n",
    "\n",
    "\n",
    "### What model can i use?\n",
    "* Whatever you want!\n",
    "you can review good models for the coco-OD task as a referance:\n",
    "SOTA: https://paperswithcode.com/sota/object-detection-on-coco\n",
    "Real-Time: https://paperswithcode.com/sota/real-time-object-detection-on-coco\n",
    "Or you can use older models like YOLO-V3 or Faster-RCNN\n",
    "* As long as you have a reason (complexity, speed, preformence), you are golden.\n",
    "\n",
    "### Tips for a good grade:\n",
    "* start as simple as possible. dealing with APIs are not the easiest for the first time and i predict that this would be your main issue. only when you have a running model that learn, you can add learning tricks.\n",
    "* use the visualization of a notebook, as we did over the course, check that your input actually fitting the model, the output is the desired size and so on.\n",
    "* It is recommanded to change the images to a fixed size, like shown in here :https://github.com/pedropro/TACO/blob/master/detector/inspect_data.ipynb\n",
    "* Please adress the architecture and your loss function/s in this notebook. if you decided to add some loss component like the Focal loss for instance, try to show the results before and after using it.\n",
    "* Plot your losses in this notebook, any evaluation metric can be shown as a function of time and possibe to analize per class.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: This is where you should write your explanations and implement the code to display the results.\n",
    "See guidelines about what to include in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "import project.model_training as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics<=8.0.20 is required but found version=8.0.59, to fix: `pip install ultralytics<=8.0.20`\n",
      "Downloading Dataset Version Zip in TACO_train_only-1 to yolov8: 100% [126861221 / 126861221] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to TACO_train_only-1 in yolov8:: 100%|████████████████████████████████████████████████████| 2373/2373 [00:10<00:00, 226.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow project...\n",
      "Dependency ultralytics<=8.0.20 is required but found version=8.0.59, to fix: `pip install ultralytics<=8.0.20`\n",
      "Downloading Dataset Version Zip in TACO_test_set-1 to yolov8: 100% [33459346 / 33459346] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to TACO_test_set-1 in yolov8:: 100%|████████████████████████████████████████████████████████| 640/640 [00:02<00:00, 281.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# run this block only on a first run \n",
    "# download the datasets\n",
    "train_set, test_set = mt.load_datasets()\n",
    "\n",
    "# edit the test_set to fit future evaluations\n",
    "# %run project/edit_test.py\n",
    "\n",
    "# store datasets for future usage\n",
    "# %store train_set\n",
    "# %store test_set\n",
    "# %store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "test_set              -> <roboflow.core.dataset.Dataset object at 0x7f3b208\n",
      "train_set             -> <roboflow.core.dataset.Dataset object at 0x7f39fa3\n"
     ]
    }
   ],
   "source": [
    "# if youve already downloaded the datasets in the past, you can restore them here:\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.59 🚀 Python-3.8.12 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11178MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/home/muradek/Deep_project/TACO_train_only-1/data.yaml, epochs=10, patience=5, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train23\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5588197  ultralytics.nn.modules.Detect                [7, [256, 512, 512]]          \n",
      "Model summary: 365 layers, 43635237 parameters, 43635221 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/muradek/Deep_project/TACO_train_only-1/train/labels.cache... 1064 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1064/1064 [00:00<?,\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/muradek/Deep_project/TACO_train_only-1/valid/labels.cache... 118 images, 0 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/\u001b[0m\n",
      "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "Plotting labels to runs/detect/train23/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train23\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.06G       1.02      3.292      1.189          6        640:  98%|█████████▊| 522/532 [01:45<00:01,  5.12it/s]"
     ]
    }
   ],
   "source": [
    "# in the first run, download the model\n",
    "model, train_res = mt.set_model(train_set, \"yolov8l.pt\")\n",
    "\n",
    "# in future runs, load the existing model\n",
    "# model = YOLO(\"runs/detect/train21/weights/best.pt\") # edit path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.59 🚀 Python-3.8.12 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11178MiB)\n",
      "Model summary (fused): 268 layers, 43612005 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/muradek/Deep_project/TACO_test_set-1/valid/labels... 317 images, 0 backgrounds, 0 corrupt: 100%|██████████| 317/317 [00:00\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/muradek/Deep_project/TACO_test_set-1/valid/labels.cache\n",
      "This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n",
      "                   all        317        957     0.0269      0.464     0.0417     0.0303\n",
      "                   bio        317         32          0          0          0          0\n",
      "                 glass        317        475      0.121      0.608      0.165      0.121\n",
      "    metals_and_plastic        317        262     0.0143      0.698     0.0608     0.0448\n",
      "        non_recyclable        317          1   0.000103          1    0.00163    0.00146\n",
      "                 other        317         47     0.0102     0.0213    0.00574    0.00516\n",
      "                 paper        317        140     0.0158      0.457      0.017    0.00989\n",
      "Speed: 2.9ms preprocess, 22.7ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Saving runs/detect/val12/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val12\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished evaluating\n"
     ]
    }
   ],
   "source": [
    "# predict with the model on the test set for evaluation \n",
    "test_res = mt.evaluate_model(test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "db2aeb4a2d20d8f60ca10a95a693e4fbc8d4e86da5b1f77d6fc445990905a603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
