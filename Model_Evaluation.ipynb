{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163eac58-a894-4012-8844-4da8ba0f1df0",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "$$\n",
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de4bda-dad5-4e66-b27e-ecf429c8cd5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation Overview:\n",
    "We chose to approach the task by training a model using the YOLO8 model. This model is regarded as one of the leading models in image classification, detection and segmentation. To be able to train and test the model on the given data set we used the RoboFlow API to preproccess the dataset. \n",
    "\n",
    "#TODO add depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44dfe35-6504-4d65-8d5f-e6fc111c7cbb",
   "metadata": {},
   "source": [
    "### Code Structure:\n",
    "#TODO How to run and reproduce the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda3e08-06c3-454a-97aa-15ef1152458f",
   "metadata": {},
   "source": [
    "### External Code Usage:\n",
    "\n",
    "#TODO write about roboflow usage and YOLO. Coco Eval tools?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76a145-81a6-4afe-8b5e-ce5b3037100c",
   "metadata": {},
   "source": [
    "### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18818fe-d7fa-4852-9dc0-fc457782c516",
   "metadata": {},
   "source": [
    "\n",
    "#### Architecture:\n",
    "YOLO V8 consists of two main components. A backbone and a head. The backbone is a series of convolutional networks and course to fine (C2f) layers. The backbone creates features which are then passed to the head for detection using the models loss function. A diagram by [RangeKing](https://github.com/RangeKing) of the model can be seen here.\n",
    "\n",
    "<div>\n",
    "<img src=\"imgs/yolov8_architecture_diagram.jpeg\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "Sublayers are included in the diagram and it illustrates each well.\n",
    "\n",
    "The architecture utilizes bottlenecks and a pyramidal structure for the architecture. One pyramidal concept is the spatial pyramid pooling layers (SPP/SPPF).\n",
    "\n",
    "Some changes in this version of YOLO include;  \n",
    "    - Not using anchor boxes for detection which increased speed.\n",
    "    - A new backbone consisting of new convolutional building block and new C2f layers which have additional residual connections.\n",
    "    - And new loss functions\n",
    "    \n",
    "The full model can bee seen here on the [YOLOv8 repo](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/v8/yolov8.yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8563733-8435-4e0e-b2f3-afe72d69b828",
   "metadata": {},
   "source": [
    "#### Loss function:\n",
    "\n",
    "The model uses a loss function that combines several elements to measure the total loss.\n",
    "\n",
    "- The first part is a Bbox Loss. The bbox loss returns two seperate loss values. \n",
    "\n",
    "1. IoU Loss: Which is a standard intersection over union loss. Calculated by using an external bbox_iou method.\n",
    "\n",
    "2. DFL Loss: Which is a distributional focal loss function. As proposed in this [paper](https://ieeexplore.ieee.org/document/9792391).\n",
    "\n",
    "Below is the code of the Bbox loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb46cc6-d3b4-468d-8985-946e3fbbd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BboxLoss(nn.Module):\n",
    "\n",
    "#     def __init__(self, reg_max, use_dfl=False):\n",
    "#         super().__init__()\n",
    "#         self.reg_max = reg_max\n",
    "#         self.use_dfl = use_dfl\n",
    "\n",
    "#     def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):\n",
    "#         # IoU loss\n",
    "#         weight = torch.masked_select(target_scores.sum(-1), fg_mask).unsqueeze(-1)\n",
    "#         iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)\n",
    "#         loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum\n",
    "\n",
    "#         # DFL loss\n",
    "#         if self.use_dfl:\n",
    "#             target_ltrb = bbox2dist(anchor_points, target_bboxes, self.reg_max)\n",
    "#             loss_dfl = self._df_loss(pred_dist[fg_mask].view(-1, self.reg_max + 1), target_ltrb[fg_mask]) * weight\n",
    "#             loss_dfl = loss_dfl.sum() / target_scores_sum\n",
    "#         else:\n",
    "#             loss_dfl = torch.tensor(0.0).to(pred_dist.device)\n",
    "\n",
    "#         return loss_iou, loss_dfl\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _df_loss(pred_dist, target):\n",
    "#         # Return sum of left and right DFL losses\n",
    "#         # Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "#         tl = target.long()  # target left\n",
    "#         tr = tl + 1  # target right\n",
    "#         wl = tr - target  # weight left\n",
    "#         wr = 1 - wl  # weight right\n",
    "#         return (F.cross_entropy(pred_dist, tl.view(-1), reduction='none').view(tl.shape) * wl +\n",
    "#                 F.cross_entropy(pred_dist, tr.view(-1), reduction='none').view(tl.shape) * wr).mean(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb524aa5-fc0e-46e0-99e7-10b98ea7f287",
   "metadata": {},
   "source": [
    "- The second part is a Varifocal loss. Which as defined  \n",
    "\n",
    "<div>\n",
    "<img src=\"imgs/VFL3.png\" width=\"500\"/>\n",
    "</div>\n",
    "<div>\n",
    "<img src=\"imgs/VFL2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "in this [paper](https://arxiv.org/pdf/2008.13367.pdf) \n",
    "\n",
    "Which is a take on binary cross entropy and is further explained in detail in the paper. \n",
    "\n",
    "We can see that the code of the loss function also includes an existing binary cross entropy method: binary_cross_entropy_with_logits\n",
    "\n",
    "Which from its documentation is a combination of binary cross entropy with a sigmoid layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99db4f15-7133-4fd7-8c08-913ca4e58beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class VarifocalLoss(nn.Module):\n",
    "#     # Varifocal loss by Zhang et al. https://arxiv.org/abs/2008.13367\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, pred_score, gt_score, label, alpha=0.75, gamma=2.0):\n",
    "#         weight = alpha * pred_score.sigmoid().pow(gamma) * (1 - label) + gt_score * label\n",
    "#         with torch.cuda.amp.autocast(enabled=False):\n",
    "#             loss = (F.binary_cross_entropy_with_logits(pred_score.float(), gt_score.float(), reduction='none') *\n",
    "#                     weight).sum()\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8275fc0-4157-44e7-a47d-85bda54da178",
   "metadata": {},
   "source": [
    "#### Optimization: \n",
    "\n",
    "The YOLOv8 model uses a default optimizer of ADAM with the following default hyper parameters.\n",
    "\n",
    "Learning rate=0.001, Momentum=0.9, Decay=1e-5\n",
    "\n",
    "We choose to use this optimizer relying on the fact that ADAM is a SOTA optimization algorithim and the model was designed around these hyperparams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017a313-2f74-49d9-a2fd-fb39189395b6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### Additional evaluation metrics?\n",
    "#### Accuracy:\n",
    "#### Results:\n",
    "#### Conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dad92a-7240-4a2c-ba94-3d36816d4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
